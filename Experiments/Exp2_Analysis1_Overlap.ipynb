{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dafa765b",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Token-based Decision Criteria Are Suboptimal in In-context Learning\" (NAACL 2025)**:\n",
    "\n",
    "### Source code for the Analysis in Sec. 5.1.\n",
    "\n",
    "The code for the main experiments of the paper: test the performance of Hidden Calibration and other methods on the in-context learning task.\n",
    "\n",
    "Used in experiments of:\n",
    "\n",
    "1. The experiments described in the Sec 5.1, and results are shown in the Fig. 7, 8, 9 of the paper.\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f15740",
   "metadata": {},
   "source": [
    "**Experiment Configs**\n",
    "\n",
    "- `huggingface_model_name`: should be a model name from the HuggingFace model hub. For example, `facebook/opt-2.7b`.\n",
    "- `huggingface_token`: should be a HuggingFace API token. Only is used when you use some models like `Llama2`.\n",
    "- `quantization`: should be a boolean value. If it is `True`, the model will be quantized.\n",
    "- `dataset_name`: should be a dataset name from the given examples: `\"SemEvalR\", \"SemEvalL\", \"poem_sentiment\", \"TEE\", \"TEH\", \"TES\", \"FP\", \"AGNews\", \"MR\", \"hate_speech\"`\n",
    "- `k`: the demonstration numbers for the ICL.\n",
    "- `calibration_sample_number_for_each_label`: the number of samples for calibration w.r.t. each label category for some of the calibration methods. i.e. the horizontal axis of the Fig. 6 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb11735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "huggingface_model_name = \"facebook/opt-2.7b\"\n",
    "huggingface_token = \"API_TOKEN\"\n",
    "quantization = False\n",
    "\n",
    "dataset_name = \"SemEvalR\" # Alternative: \"SemEvalR\", \"SemEvalL\", \"poem_sentiment\", \"TEE\", \"TEH\", \"TES\", \"FP\", \"AGNews\", \"MR\", \"hate_speech\"\n",
    "\n",
    "k = 4\n",
    "calibration_sample_number_for_each_label = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac664c9",
   "metadata": {},
   "source": [
    "**Load everything.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, and nessessary definitions\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"hidden_calibration_released\") # Replace with the path from the working directory to the root of this project. If the working directory is already the root of the project, this line is not needed.\n",
    "\n",
    "import util.prompting as prompting\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import util.dataset_loader as dataset_loader\n",
    "import util.calibrations as calibrations\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "\n",
    "def softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "dataset_name_to_class = {\n",
    "    \"SemEvalR\": dataset_loader.SemEval2014_Restaurants,\n",
    "    \"SemEvalL\": dataset_loader.SemEval2014_Laptops,\n",
    "    \"poem_sentiment\": dataset_loader.poem_sentiment,\n",
    "    \"TEE\": dataset_loader.tweet_eval_emotion,\n",
    "    \"TEH\": dataset_loader.tweet_eval_hate,\n",
    "    \"TES\": dataset_loader.tweet_eval_sentiment,\n",
    "    \"FP\": dataset_loader.financial_phrasebank,\n",
    "    \"AGNews\": dataset_loader.agnews,\n",
    "    \"MR\": dataset_loader.rooten_tomato,\n",
    "    \"hate_speech\": dataset_loader.hate_speech18,\n",
    "}\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('font',family='Times New Roman')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f17860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer from Huggingface\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name, token = huggingface_token)\n",
    "if quantization:\n",
    "    model = AutoModelForCausalLM.from_pretrained(huggingface_model_name, token = huggingface_token, quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    ))\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(huggingface_model_name, token = huggingface_token).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e287b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "\n",
    "train_data = dataset_name_to_class[dataset_name]().default_training_division()\n",
    "test_data = dataset_name_to_class[dataset_name]().default_testing_division()\n",
    "if dataset_name == \"AGNews\":\n",
    "    train_data.cut_by_length(226)\n",
    "    test_data.cut_by_length(226)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3572c145",
   "metadata": {},
   "source": [
    "**Train all the calibration methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c233d-16a1-461c-aaf4-81e3ea00c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Contextual Calibration and Domain Calibration\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "observed_background_prob_for_CC = calibrations.empty_query_base_logits(model, tokenizer, train_data, k, None, calibration_sample_number_for_each_label * len(train_data.label_space))\n",
    "observed_background_prob_for_DC = calibrations.domain_text_base_logits(model, tokenizer, train_data, k, None, calibration_sample_number_for_each_label * len(train_data.label_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8273a12-ab97-4667-9adc-2f691f56ab08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the Hidden Calibration\n",
    "\n",
    "## Collect the hidden states for the calibration samples.\n",
    "ground_truth_labels_for_calibration_samples = []\n",
    "observed_full_vocabulary_probabilities = []\n",
    "observed_last_hidden_state = []\n",
    "\n",
    "torch.no_grad()\n",
    "for j in range(len(train_data.label_space)):\n",
    "    label_set = dataset_loader.get_label_set_from_label_index(train_data, j)\n",
    "    for i in tqdm(label_set[:calibration_sample_number_for_each_label]):\n",
    "        torch.cuda.empty_cache()\n",
    "        prpt = prompting.default_prompting(train_data, k, query_index=i)\n",
    "        tknzd_data = tokenizer(prpt[0], return_tensors=\"pt\").input_ids.cuda()\n",
    "        result = model(tknzd_data, output_hidden_states = True)\n",
    "        result_vector = result['logits'][0][-1].detach().cpu().numpy()\n",
    "        one_last_hidden_state = result.hidden_states[-1][-1][-1].detach().cpu().numpy()\n",
    "        observed_last_hidden_state.append(one_last_hidden_state)\n",
    "        tkized_label_space = []\n",
    "        ground_truth_labels_for_calibration_samples.append(train_data.label_space.index(prpt[1]))\n",
    "\n",
    "## Divide the collected hidden states by label.\n",
    "observed_last_hidden_state_indexed_by_label = []\n",
    "\n",
    "for label in train_data.label_space:\n",
    "    observed_last_hidden_state_indexed_by_label.append([])\n",
    "for i in range(len(ground_truth_labels_for_calibration_samples)):\n",
    "    observed_last_hidden_state_indexed_by_label[ground_truth_labels_for_calibration_samples[i]].append(observed_last_hidden_state[i])\n",
    "\n",
    "## Calculate the centroids from the collected hidden states\n",
    "observed_last_hidden_state_CENTROID_indexed_by_label = []\n",
    "for lists in observed_last_hidden_state_indexed_by_label:\n",
    "    observed_last_hidden_state_CENTROID_indexed_by_label.append(np.mean(lists, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941f92d",
   "metadata": {},
   "source": [
    "**Inference and calculate the overlap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5626938a-f094-4dd2-9bd4-5c0599c6ad2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store: the inference output of each input sample, index by the input sample's ground truth label.\n",
    "\n",
    "logits_set_wrt_gt_label = []\n",
    "hidden_state_set_wrt_gt_label = []\n",
    "for i in range(len(train_data.label_space)):\n",
    "    logits_set_wrt_gt_label.append([])\n",
    "    hidden_state_set_wrt_gt_label.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72bd29b-a5a3-4b35-b290-d71576d35752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill the aforementioned list by inference\n",
    "\n",
    "count = 0\n",
    "correct_predicted_hidden_calibration = 0\n",
    "correct_predicted_vanilla = 0\n",
    "\n",
    "torch.no_grad()\n",
    "for i in tqdm(range(test_data.get_max())):\n",
    "    count += 1\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_single = []\n",
    "    prpt = prompting.default_prompting(test_data, k, query_index=i)\n",
    "    tknzd_data = tokenizer(prpt[0], return_tensors=\"pt\").input_ids.cuda()\n",
    "    result = model(tknzd_data, output_hidden_states = True)\n",
    "    result_vector = result['logits'][0][-1].detach().cpu().numpy()\n",
    "    ahidden_state = result.hidden_states[-1][-1][-1].detach().cpu().numpy()\n",
    "    direct_label_logits = []\n",
    "    # hidden_set_wrt_label[test_data.label_space.index(prpt[1])].append(ahidden_state)\n",
    "    \n",
    "    for label in test_data.label_space:\n",
    "        index = tokenizer(label).input_ids[-1]\n",
    "        direct_label_logits.append(result_vector[index])\n",
    "    direct_label_logits = softmax(direct_label_logits)\n",
    "    logits_set_wrt_gt_label[test_data.label_space.index(prpt[1])].append(direct_label_logits)\n",
    "    \n",
    "    if test_data.label_space.index(prpt[1]) == np.argmax(direct_label_logits):\n",
    "        correct_predicted_vanilla += 1\n",
    "    \n",
    "    distance_label_logits = []\n",
    "    for j in range(len(train_data.label_space)):\n",
    "        distance_label_logits.append(-spatial.distance.euclidean(ahidden_state, observed_last_hidden_state_CENTROID_indexed_by_label[j]) + 15)\n",
    "    hidden_state_set_wrt_gt_label[test_data.label_space.index(prpt[1])].append(softmax(distance_label_logits))\n",
    "    \n",
    "    if test_data.label_space.index(prpt[1]) == np.argmax(distance_label_logits):\n",
    "        correct_predicted_hidden_calibration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d176dbf2-a950-4cb7-b93e-432787963cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the heatmap and mean lists for the results.\n",
    "\n",
    "vanilla_result_heatmap = []\n",
    "hidden_result_heatmap = []\n",
    "contextual_result_heatmap = []\n",
    "domain_result_heatmap = []\n",
    "vanilla_result_mean = []\n",
    "hidden_result_mean = []\n",
    "contextual_result_mean = []\n",
    "domain_result_mean = []\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    vanilla_result_heatmap.append([0] * len(train_data.label_space))\n",
    "    hidden_result_heatmap.append([0] * len(train_data.label_space))\n",
    "    contextual_result_heatmap.append([0] * len(train_data.label_space))\n",
    "    domain_result_heatmap.append([0] * len(train_data.label_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188876c8-736b-4f39-a75b-734a48673a3b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the overlap results by vanilla ICL, fill the corresponding heatmap and mean lists for the results, and show the density plots.\n",
    "# Calculation described in the Appendix B.5.1.\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    for j in range(i):\n",
    "        logist_distribution_labeli = []\n",
    "        logist_distribution_labelj = []\n",
    "        for res in logits_set_wrt_gt_label[i]:\n",
    "            logist_distribution_labeli.append(res[i] - res[j])\n",
    "        for res in logits_set_wrt_gt_label[j]:\n",
    "            logist_distribution_labelj.append(res[i] - res[j])\n",
    "        density1 = gaussian_kde(logist_distribution_labeli)\n",
    "        density2 = gaussian_kde(logist_distribution_labelj)\n",
    "        x = np.linspace(min(min(logist_distribution_labeli), min(logist_distribution_labelj)), \n",
    "                        max(max(logist_distribution_labeli), max(logist_distribution_labelj)), 500)\n",
    "        overlap_area = np.trapz(np.minimum(density1(x), density2(x)), x)\n",
    "        vanilla_result_heatmap[i][j] = overlap_area\n",
    "        vanilla_result_mean.append(overlap_area)\n",
    "        \n",
    "        plt.figure(figsize=(4, 4), dpi=300)\n",
    "        plt.plot(x, density1(x), \n",
    "                 label='Positive Samples', \n",
    "                 color='Royalblue',\n",
    "                 linewidth = 3)\n",
    "        plt.plot(x, density2(x), \n",
    "                 label='Negative Samples', \n",
    "                 color='Coral',\n",
    "                 linewidth = 3)\n",
    "        plt.fill_between(x, density1(x), 0, color='Royalblue', alpha=0.2)\n",
    "        plt.fill_between(x, density2(x), 0, color='Coral', alpha=0.2)\n",
    "        plt.legend(prop = {'size': 8})\n",
    "        plt.tick_params(width=2, labelsize=24)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bf6b1-83a3-45b8-845d-dd719243b59c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the overlap results by contextual calibration, fill the corresponding heatmap and mean lists for the results, and show the density plots.\n",
    "# Calculation described in the Appendix B.5.1.\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    for j in range(i):\n",
    "        con_distribution_labeli = []\n",
    "        con_distribution_labelj = []\n",
    "        for res in logits_set_wrt_gt_label[i]:\n",
    "            con_distribution_labeli.append(res[i] / observed_background_prob_for_CC[i] - res[j] / observed_background_prob_for_CC[j])\n",
    "        for res in logits_set_wrt_gt_label[j]:\n",
    "            con_distribution_labelj.append(res[i] / observed_background_prob_for_CC[i] - res[j] / observed_background_prob_for_CC[j])\n",
    "        density1 = gaussian_kde(con_distribution_labeli)\n",
    "        density2 = gaussian_kde(con_distribution_labelj)\n",
    "        x = np.linspace(min(min(con_distribution_labeli), min(con_distribution_labelj)), \n",
    "                        max(max(con_distribution_labeli), max(con_distribution_labelj)), 500)\n",
    "        overlap_area = np.trapz(np.minimum(density1(x), density2(x)), x)\n",
    "        contextual_result_heatmap[i][j] = overlap_area\n",
    "        contextual_result_mean.append(overlap_area)\n",
    "        \n",
    "        plt.figure(figsize=(4, 4), dpi=300)\n",
    "        plt.plot(x, density1(x), \n",
    "                 label='Positive Samples', \n",
    "                 color='Royalblue',\n",
    "                 linewidth = 3)\n",
    "        plt.plot(x, density2(x), \n",
    "                 label='Negative Samples', \n",
    "                 color='Coral',\n",
    "                 linewidth = 3)\n",
    "        plt.fill_between(x, density1(x), 0, color='Royalblue', alpha=0.2)\n",
    "        plt.fill_between(x, density2(x), 0, color='Coral', alpha=0.2)\n",
    "        plt.legend(prop = {'size': 8})\n",
    "        plt.tick_params(width=2, labelsize=24)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557b960-bd72-4323-9ce1-c9973a9b40b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the overlap results by domain calibration, fill the corresponding heatmap and mean lists for the results, and show the density plots.\n",
    "# Calculation described in the Appendix B.5.1.\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    for j in range(i):\n",
    "        con_distribution_labeli = []\n",
    "        con_distribution_labelj = []\n",
    "        for res in logits_set_wrt_gt_label[i]:\n",
    "            con_distribution_labeli.append(res[i] / observed_background_prob_for_DC[i] - res[j] / observed_background_prob_for_DC[j])\n",
    "        for res in logits_set_wrt_gt_label[j]:\n",
    "            con_distribution_labelj.append(res[i] / observed_background_prob_for_DC[i] - res[j] / observed_background_prob_for_DC[j])\n",
    "        density1 = gaussian_kde(con_distribution_labeli)\n",
    "        density2 = gaussian_kde(con_distribution_labelj)\n",
    "        x = np.linspace(min(min(con_distribution_labeli), min(con_distribution_labelj)), \n",
    "                        max(max(con_distribution_labeli), max(con_distribution_labelj)), 500)\n",
    "        overlap_area = np.trapz(np.minimum(density1(x), density2(x)), x)\n",
    "        domain_result_heatmap[i][j] = overlap_area\n",
    "        domain_result_mean.append(overlap_area)\n",
    "        \n",
    "        plt.figure(figsize=(4, 4), dpi=300)\n",
    "        plt.plot(x, density1(x), \n",
    "                 label='Positive Samples', \n",
    "                 color='Royalblue',\n",
    "                 linewidth = 3)\n",
    "        plt.plot(x, density2(x), \n",
    "                 label='Negative Samples', \n",
    "                 color='Coral',\n",
    "                 linewidth = 3)\n",
    "        plt.fill_between(x, density1(x), 0, color='Royalblue', alpha=0.2)\n",
    "        plt.fill_between(x, density2(x), 0, color='Coral', alpha=0.2)\n",
    "        plt.legend(prop = {'size': 8})\n",
    "        plt.tick_params(width=2, labelsize=24)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb47a0-8a78-4ee3-a97a-425764395e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the overlap results by hidden calibration, fill the corresponding heatmap and mean lists for the results, and show the density plots.\n",
    "# Calculation described in the Appendix B.5.1.\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    for j in range(i):\n",
    "        hidden_distribution_labeli = []\n",
    "        hidden_distribution_labelj = []\n",
    "        for res in hidden_state_set_wrt_gt_label[i]:\n",
    "            hidden_distribution_labeli.append(res[i] - res[j])\n",
    "        for res in hidden_state_set_wrt_gt_label[j]:\n",
    "            hidden_distribution_labelj.append(res[i] - res[j])\n",
    "        density1 = gaussian_kde(hidden_distribution_labeli)\n",
    "        density2 = gaussian_kde(hidden_distribution_labelj)\n",
    "        x = np.linspace(min(min(hidden_distribution_labeli), min(hidden_distribution_labelj)), \n",
    "                        max(max(hidden_distribution_labeli), max(hidden_distribution_labelj)), 500)\n",
    "        overlap_area = np.trapz(np.minimum(density1(x), density2(x)), x)\n",
    "        hidden_result_heatmap[i][j] = overlap_area\n",
    "        hidden_result_mean.append(overlap_area)\n",
    "        \n",
    "        plt.figure(figsize=(4, 4), dpi=300)\n",
    "        plt.plot(x, density1(x), \n",
    "                 label='Positive Samples', \n",
    "                 color='Royalblue',\n",
    "                 linewidth = 3)\n",
    "        plt.plot(x, density2(x), \n",
    "                 label='Negative Samples', \n",
    "                 color='Coral',\n",
    "                 linewidth = 3)\n",
    "        plt.fill_between(x, density1(x), 0, color='Royalblue', alpha=0.2)\n",
    "        plt.fill_between(x, density2(x), 0, color='Coral', alpha=0.2)\n",
    "        plt.legend(prop = {'size': 8})\n",
    "        plt.tick_params(width=2, labelsize=24)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511c3e6-22c6-4266-bd16-c3f49730042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final result report.\n",
    "\n",
    "print(\"Result report on \" + dataset_name + \" dataset, metric: Inter-category overlap\\n\")\n",
    "\n",
    "print(\"vanilla ICL: \" + str(np.mean(vanilla_result_mean)))\n",
    "print(\"hidden calibration: \" + str(np.mean(hidden_result_mean)))\n",
    "print(\"contextual calibration: \" + str(np.mean(contextual_result_mean)))\n",
    "print(\"domain calibration: \" + str(np.mean(domain_result_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b20e56",
   "metadata": {},
   "source": [
    "**Draw the heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6a77f-c7e1-4b83-9684-90cdf33c395a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The heatmap for vanilla ICL.\n",
    "\n",
    "for i in range(len(train_data.label_space)):\n",
    "    vanilla_result_heatmap[i][i] = 1\n",
    "    hidden_result_heatmap[i][i] = 1\n",
    "\n",
    "mask = []\n",
    "for i in range(len(train_data.label_space)):\n",
    "    temp_mask = [0] * (i+1) + [1] * (len(train_data.label_space)-i-1)\n",
    "    mask.append(temp_mask)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=300)\n",
    "sns.heatmap(\n",
    "    vanilla_result_heatmap, \n",
    "    vmin = 0,\n",
    "    vmax = 1,\n",
    "    mask = np.array(mask), \n",
    "    annot=True, \n",
    "    cbar=False,\n",
    "    linewidths=2,\n",
    "    cmap = \"Reds\",\n",
    "    annot_kws={\"fontsize\":20}\n",
    ")\n",
    "ax=plt.gca()\n",
    "ax.set_xticklabels(train_data.label_space, fontsize=16)\n",
    "ax.set_yticklabels(train_data.label_space, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126df513-c0d8-4b4b-ac23-be2307748935",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The heatmap for hidden calibration.\n",
    "\n",
    "mask = []\n",
    "for i in range(len(train_data.label_space)):\n",
    "    temp_mask = [0] * (i+1) + [1] * (len(train_data.label_space)-i-1)\n",
    "    mask.append(temp_mask)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=300)\n",
    "sns.heatmap(\n",
    "    hidden_result_heatmap, \n",
    "    vmin = 0,\n",
    "    vmax = 1,\n",
    "    mask = np.array(mask), \n",
    "    annot=True, \n",
    "    cbar=False,\n",
    "    linewidths=2,\n",
    "    cmap = \"Reds\",\n",
    "    annot_kws={\"fontsize\":20}\n",
    ")\n",
    "ax=plt.gca()\n",
    "ax.set_xticklabels(train_data.label_space, fontsize=16)\n",
    "ax.set_yticklabels(train_data.label_space, fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
