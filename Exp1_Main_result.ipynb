{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6e5855",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Token-based Decision Criteria Are Suboptimal in In-context Learning\" (NAACL 2025)**:\n",
    "\n",
    "### Source code for the Main Experiment\n",
    "\n",
    "The code for the main experiments of the paper: test the performance of Hidden Calibration and other methods on the in-context learning task.\n",
    "\n",
    "Used in experiments of:\n",
    "\n",
    "1. The experiments described in the Sec 4, and results are shown in the Sec 4.2 of the paper.\n",
    "2. The experiments described in the Sec 4.3, of the Prompt Template Complexity, shown in Fig. 5 (left), by varying the prompt template parameter of `prompt_function`.\n",
    "3. The experiments described in the Sec 4.3, of the Demonstration Sampling / Order Complexity, shown in Fig. 5 (middle, right), by varying the `pre_sampled_demonstration` parameter of `prompt_function`.\n",
    "4. Also, the data efficiency experiment (Sec 4.3, Training Data Complexity, Fig. 6) reuses this code by varying the parameter `calibration_sample_number_for_each_label`.\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9a5c0",
   "metadata": {},
   "source": [
    "**Experiment Configs**\n",
    "\n",
    "- `huggingface_model_name`: should be a model name from the HuggingFace model hub. For example, `facebook/opt-2.7b`.\n",
    "- `huggingface_token`: should be a HuggingFace API token. Only is used when you use some models like `Llama2`.\n",
    "- `quantization`: should be a boolean value. If it is `True`, the model will be quantized.\n",
    "- `dataset_name`: should be a dataset name from the given examples: `\"SemEvalR\", \"SemEvalL\", \"poem_sentiment\", \"TEE\", \"TEH\", \"TES\", \"FP\", \"AGNews\", \"MR\", \"hate_speech\"`\n",
    "- `k`: the demonstration numbers for the ICL.\n",
    "- `calibration_sample_number_for_each_label`: the number of samples for calibration w.r.t. each label category for some of the calibration methods. i.e. the horizontal axis of the Fig. 6 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d28046ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "huggingface_model_name = \"facebook/opt-2.7b\"\n",
    "huggingface_token = \"API_TOKEN\"\n",
    "quantization = False\n",
    "\n",
    "dataset_name = \"SemEvalR\" # Alternative: \"SemEvalR\", \"SemEvalL\", \"poem_sentiment\", \"TEE\", \"TEH\", \"TES\", \"FP\", \"AGNews\", \"MR\", \"hate_speech\"\n",
    "\n",
    "k = 4\n",
    "calibration_sample_number_for_each_label = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e3d7d",
   "metadata": {},
   "source": [
    "**Load everything.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5018248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, and nessessary definitions\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"hidden_calibration_released\") # Replace with the path from the working directory to the root of this project. If the working directory is already the root of the project, this line is not needed.\n",
    "\n",
    "from functools import partial\n",
    "import util.prompting as prompting\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import util.dataset_loader as dataset_loader\n",
    "import util.calibrations as calibrations\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics.functional import multiclass_accuracy, multiclass_f1_score\n",
    "from scipy import spatial\n",
    "import copy\n",
    "\n",
    "def softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "dataset_name_to_class = {\n",
    "    \"SemEvalR\": dataset_loader.SemEval2014_Restaurants,\n",
    "    \"SemEvalL\": dataset_loader.SemEval2014_Laptops,\n",
    "    \"poem_sentiment\": dataset_loader.poem_sentiment,\n",
    "    \"TEE\": dataset_loader.tweet_eval_emotion,\n",
    "    \"TEH\": dataset_loader.tweet_eval_hate,\n",
    "    \"TES\": dataset_loader.tweet_eval_sentiment,\n",
    "    \"FP\": dataset_loader.financial_phrasebank,\n",
    "    \"AGNews\": dataset_loader.agnews,\n",
    "    \"MR\": dataset_loader.rooten_tomato,\n",
    "    \"hate_speech\": dataset_loader.hate_speech18,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "89f3caa6-309d-4730-bf56-0e062f001471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model and tokenizer from Huggingface\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name, token = huggingface_token)\n",
    "if quantization:\n",
    "    model = AutoModelForCausalLM.from_pretrained(huggingface_model_name, token = huggingface_token, quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    ))\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(huggingface_model_name, token = huggingface_token).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "75fbb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset_name_to_class[dataset_name]().default_training_division()\n",
    "test_data = dataset_name_to_class[dataset_name]().default_testing_division()\n",
    "if dataset_name == \"AGNews\":\n",
    "    train_data.cut_by_length(226)\n",
    "    test_data.cut_by_length(226)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f9288",
   "metadata": {},
   "source": [
    "Define the prompt template by:\n",
    "\n",
    "``` python\n",
    "default_prompting(dataset, demos_amount, query_index = -1, input_start = 'Input: ', input_end_label_start = ', Label: ', inter_div = '\\n')\n",
    "```\n",
    "where, `dataset` is the dataset name, `demos_amount` is the number of demonstrations, `query_index` is the index of the query, `input_start` is what in the start of the input text, `input_end_label_start` is what in the end of the input text and the start of the label, `inter_div` is the division between the input and the label.\n",
    "\n",
    "Recommand to use `partial` to define the template by setting the `input_start`, `input_end_label_start`, `inter_div`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2396ade3-9b4b-421b-9f76-e2922b1b3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_function = partial(prompting.default_prompting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a04fb2",
   "metadata": {},
   "source": [
    "**Train all the calibration methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532741bb-ce03-47e5-85ad-200c20a12097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the Contextual Calibration and Domain Calibration\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "observed_background_prob_for_CC = calibrations.empty_query_base_logits(model, tokenizer, train_data, k, prompt_function, calibration_sample_number_for_each_label * len(train_data.label_space))\n",
    "observed_background_prob_for_DC = calibrations.domain_text_base_logits(model, tokenizer, train_data, k, prompt_function, calibration_sample_number_for_each_label * len(train_data.label_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7b936-5873-4b83-b27d-37eba4dad0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the Centroid Calibration and Hidden Calibration\n",
    "\n",
    "## Collect the hidden states and full vocabulary probabilities for the calibration samples.\n",
    "ground_truth_labels_for_calibration_samples = []\n",
    "observed_full_vocabulary_probabilities = []\n",
    "observed_last_hidden_state = []\n",
    "\n",
    "torch.no_grad()\n",
    "for j in range(len(train_data.label_space)):\n",
    "    label_set = dataset_loader.get_label_set_from_label_index(train_data, j)\n",
    "    for i in tqdm(label_set[:calibration_sample_number_for_each_label]):\n",
    "        torch.cuda.empty_cache()\n",
    "        prpt = prompt_function(train_data, k, query_index=i)\n",
    "        tknzd_data = tokenizer(prpt[0], return_tensors=\"pt\").input_ids.cuda()\n",
    "        result = model(tknzd_data, output_hidden_states = True)\n",
    "        result_vector = result['logits'][0][-1].detach().cpu().numpy()\n",
    "        one_last_hidden_state = result.hidden_states[-1][-1][-1].detach().cpu().numpy()\n",
    "        observed_last_hidden_state.append(one_last_hidden_state)\n",
    "        tkized_label_space = []\n",
    "        observed_full_vocabulary_probabilities.append(softmax(result_vector))\n",
    "        ground_truth_labels_for_calibration_samples.append(train_data.label_space.index(prpt[1]))\n",
    "\n",
    "## Divide the collected hidden states and full vocabulary probabilities by label.\n",
    "observed_full_vocabulary_probabilities_indexed_by_label = []\n",
    "observed_last_hidden_state_indexed_by_label = []\n",
    "\n",
    "for label in train_data.label_space:\n",
    "    observed_full_vocabulary_probabilities_indexed_by_label.append([])\n",
    "    observed_last_hidden_state_indexed_by_label.append([])\n",
    "for i in range(len(ground_truth_labels_for_calibration_samples)):\n",
    "    observed_full_vocabulary_probabilities_indexed_by_label[ground_truth_labels_for_calibration_samples[i]].append(observed_full_vocabulary_probabilities[i])\n",
    "    observed_last_hidden_state_indexed_by_label[ground_truth_labels_for_calibration_samples[i]].append(observed_last_hidden_state[i])\n",
    "\n",
    "## Calculate the centroids from the collected hidden states and full vocabulary probabilities.\n",
    "observed_full_vocabulary_probabilities_CENTROID_indexed_by_label = []\n",
    "observed_last_hidden_state_CENTROID_indexed_by_label = []\n",
    "for lists in observed_full_vocabulary_probabilities_indexed_by_label:\n",
    "    observed_full_vocabulary_probabilities_CENTROID_indexed_by_label.append(np.mean(lists, axis=0))\n",
    "for lists in observed_last_hidden_state_indexed_by_label:\n",
    "    observed_last_hidden_state_CENTROID_indexed_by_label.append(np.mean(lists, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85981c",
   "metadata": {},
   "source": [
    "**Inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d7cc5-1ecf-4ba7-b0bd-0582f6d92306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference by vanilla model, Contextual Calibration, and Domain Calibration, and collect the hidden states and full vocabulary probabilities for Hidden Calibration and Centroid Calibration\n",
    "\n",
    "vanilla_logits_softmaxed = [] # Prepare for the Batch Calibration\n",
    "\n",
    "inference_full_vocabulary_probabilities = []\n",
    "inference_last_hidden_state = []\n",
    "\n",
    "predicted_by_vanilla = []\n",
    "predicted_by_CC = []\n",
    "predicted_by_DC = []\n",
    "predicted_by_centroid_calibration = []\n",
    "predicted_by_hidden_calibration_cosine = []\n",
    "predicted_by_hidden_calibration_L2 = []\n",
    "predicted_by_knn_withlabel = []\n",
    "groundtruth = []\n",
    "\n",
    "torch.no_grad()\n",
    "for i in tqdm(range(test_data.get_max())):\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_single = []\n",
    "    prpt = prompt_function(test_data, k, query_index=i)\n",
    "    tknzd_data = tokenizer(prpt[0], return_tensors=\"pt\").input_ids.cuda()\n",
    "    result = model(tknzd_data, output_hidden_states = True)\n",
    "    result_vector = result['logits'][0][-1].detach().cpu().numpy()\n",
    "    ahidden_state = result.hidden_states[-1][-1][-1].detach().cpu().numpy()\n",
    "    direct_label_logits = []\n",
    "    inference_last_hidden_state.append(ahidden_state)\n",
    "    inference_full_vocabulary_probabilities.append(softmax(result_vector))\n",
    "    for label in test_data.label_space:\n",
    "        index = tokenizer(label).input_ids[-1]\n",
    "        direct_label_logits.append(result_vector[index])\n",
    "    direct_label_logits = softmax(direct_label_logits)\n",
    "    vanilla_logits_softmaxed.append(direct_label_logits)\n",
    "    predicted_by_vanilla.append(np.argmax(direct_label_logits))\n",
    "    dc_direct_label_logits = copy.deepcopy(direct_label_logits)\n",
    "    for i in range(len(direct_label_logits)):\n",
    "        direct_label_logits[i] /= observed_background_prob_for_CC[i] + 1e-10\n",
    "    for i in range(len(direct_label_logits)):\n",
    "        dc_direct_label_logits[i] /= observed_background_prob_for_DC[i] + 1e-10\n",
    "    predicted_by_CC.append(np.argmax(direct_label_logits))\n",
    "    predicted_by_DC.append(np.argmax(dc_direct_label_logits))\n",
    "    groundtruth.append(test_data.label_space.index(prpt[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d66379d-6272-41a8-ae6f-610d573f9bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Predicting by Batch Calibration\n",
    "predicted_by_batch_calibration = calibrations.batch_calibration_for_result(\n",
    "    vanilla_logits_softmaxed,\n",
    "    calibration_sample_number_for_each_label\n",
    ")\n",
    "\n",
    "## Predicting by KNN\n",
    "for result_vector in inference_full_vocabulary_probabilities:\n",
    "    predicted_by_knn_withlabel.append(calibrations.predict_by_knn(result_vector, observed_full_vocabulary_probabilities, ground_truth_labels_for_calibration_samples, spatial.distance.jensenshannon, len(train_data.label_space), 3))\n",
    "\n",
    "def pdf(x, mu, sigma): \n",
    "    return 1/(sigma*np.sqrt(2*np.pi))*np.exp(-(x-mu)**2/(2*sigma**2))\n",
    "\n",
    "## Predicting by Centroid Calibration\n",
    "for result_vector in inference_full_vocabulary_probabilities:\n",
    "    predicted_single = []\n",
    "    ablation_cosine_single = []\n",
    "    ablation_l2_single = []\n",
    "    for l in range(len(observed_full_vocabulary_probabilities_CENTROID_indexed_by_label)):\n",
    "        ablation_cosine_single.append(np.abs(1 - spatial.distance.cosine(observed_full_vocabulary_probabilities_CENTROID_indexed_by_label[l], result_vector)))\n",
    "        ablation_l2_single.append(-spatial.distance.euclidean(observed_full_vocabulary_probabilities_CENTROID_indexed_by_label[l], result_vector))\n",
    "        predicted_single.append(-spatial.distance.jensenshannon(observed_full_vocabulary_probabilities_CENTROID_indexed_by_label[l], result_vector))\n",
    "    predicted_single = softmax(predicted_single)\n",
    "    predicted_by_centroid_calibration.append(np.argmax(predicted_single))\n",
    "\n",
    "## Predicting by Hidden Calibration\n",
    "for result_vector in inference_last_hidden_state:\n",
    "    cosine_single = []\n",
    "    l2_single = []\n",
    "    for l in range(len(observed_last_hidden_state_CENTROID_indexed_by_label)):\n",
    "        cosine_single.append(-spatial.distance.euclidean(observed_last_hidden_state_CENTROID_indexed_by_label[l], result_vector))\n",
    "        l2_single.append(-spatial.distance.cosine(observed_last_hidden_state_CENTROID_indexed_by_label[l], result_vector))\n",
    "    predicted_by_hidden_calibration_cosine.append(np.argmax(cosine_single))\n",
    "    predicted_by_hidden_calibration_L2.append(np.argmax(l2_single))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d405b",
   "metadata": {},
   "source": [
    "**Test and output results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ee2ce-84d7-4976-8561-867189e25283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Result report on \" + dataset_name + \" dataset, metric: Macro F1 Score\\n\")\n",
    "\n",
    "print(\"Vanilla ICL: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_vanilla), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Contextual Calibration: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_CC), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Domain Calibration: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_DC), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Batch Calibration: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_batch_calibration), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Centroid Calibration: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_centroid_calibration), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"KNN: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_knn_withlabel), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Hidden Calibration cosine: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_hidden_calibration_cosine), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Hidden Calibration L2: \" + str(multiclass_f1_score(torch.LongTensor(predicted_by_hidden_calibration_L2), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result report on \" + dataset_name + \" dataset, metric: Accuracy\\n\")\n",
    "\n",
    "print(\"Vanilla ICL: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_vanilla), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Contextual Calibration: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_CC), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Domain Calibration: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_DC), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Batch Calibration: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_batch_calibration), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Centroid Calibration: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_centroid_calibration), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"KNN: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_knn_withlabel), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Hidden Calibration cosine: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_hidden_calibration_cosine), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))\n",
    "print(\"Hidden Calibration L2: \" + str(multiclass_accuracy(torch.LongTensor(predicted_by_hidden_calibration_L2), torch.LongTensor(groundtruth), num_classes = len(test_data.label_space), average = 'macro').item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
